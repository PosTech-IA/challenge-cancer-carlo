# evaluate.py
# Fun√ß√µes para avaliar e interpretar modelos de classifica√ß√£o
# Inclui m√©tricas, gr√°ficos de confus√£o, import√¢ncia de vari√°veis e explica√ß√µes SHAP

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap

from sklearn.metrics import (
    accuracy_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report
)

def evaluate_models(models, X_test, y_test):
    """
    Avalia todos os modelos fornecidos usando m√©tricas padr√£o (acur√°cia, recall, F1-score).
    Tamb√©m imprime o relat√≥rio de classifica√ß√£o e plota a matriz de confus√£o.
    """
    for name, model in models.items():
        print(f"\nüîç Avaliando modelo: {name}")

        y_pred = model.predict(X_test)  # Faz predi√ß√µes

        acc = accuracy_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        print(f"‚úîÔ∏è Accuracy     : {acc:.4f}")
        print(f"‚úîÔ∏è Recall       : {recall:.4f}")
        print(f"‚úîÔ∏è F1-Score     : {f1:.4f}")

        print("\nüìã Classification Report:")
        print(classification_report(y_test, y_pred))

        plot_confusion_matrix(y_test, y_pred, title=f'Matriz de Confus√£o - {name}')

def plot_confusion_matrix(y_true, y_pred, title='Matriz de Confus√£o'):
    """
    Plota a matriz de confus√£o para visualizar acertos e erros do modelo.
    """
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Benigno", "Maligno"], yticklabels=["Benigno", "Maligno"])
    plt.xlabel("Predito")
    plt.ylabel("Real")
    plt.title(title)
    plt.tight_layout()
    os.makedirs('outputs/reports', exist_ok=True)
    filename = f'outputs/reports/confusion_matrix_{title.replace(' ', '_')}.png'
    plt.savefig(filename)
    print(f"üìÅ Matriz de confus√£o salva em: {filename}")
    plt.close()

def plot_feature_importance(model, feature_names, model_name="Modelo"):
    """
    Plota e salva a import√¢ncia das vari√°veis (features) para modelos que possuem o atributo 'feature_importances_'.
    """
    if not hasattr(model, "feature_importances_"):
        print(f"‚ö†Ô∏è  O modelo {model_name} n√£o possui 'feature_importances_'")
        return

    importances = model.feature_importances_
    indices = importances.argsort()[::-1]  # Ordena da mais importante para a menos

    plt.figure(figsize=(10, 6))
    plt.title(f"Import√¢ncia das Features - {model_name}")
    sns.barplot(x=importances[indices], y=[feature_names[i] for i in indices])
    plt.xlabel("Import√¢ncia")
    plt.ylabel("Vari√°vel")
    plt.tight_layout()

    os.makedirs('outputs/reports', exist_ok=True)
    filename = f'outputs/reports/feature_importance_{model_name.replace(" ", "_")}.png'
    plt.savefig(filename)
    print(f"üìÅ Gr√°fico salvo em: {filename}")

def explain_with_shap(model, X_train, feature_names, model_name="Modelo"):
    """
    Gera explica√ß√µes SHAP para o modelo, mostrando o impacto de cada vari√°vel na predi√ß√£o.
    Salva gr√°ficos summary e force plot.
    """
    print(f"\nüîç Gerando explica√ß√µes SHAP para: {model_name}")
    
    explainer = shap.Explainer(model, X_train)
    shap_values = explainer(X_train)

    # SHAP summary plot (resumo global das import√¢ncias)
    shap.summary_plot(shap_values, features=X_train, feature_names=feature_names, show=False)
    os.makedirs('outputs/reports', exist_ok=True)
    summary_path = f'outputs/reports/shap_summary_{model_name.replace(" ", "_")}.png'
    plt.savefig(summary_path)
    print(f"üìÅ SHAP summary salvo em: {summary_path}")

    # SHAP force plot (explica√ß√£o individual)
    force_path = f'outputs/reports/shap_force_{model_name.replace(" ", "_")}.html'
    shap.save_html(force_path, shap.plots.force(shap_values[0]))
    print(f"üìÅ SHAP force plot salvo em: {force_path}")