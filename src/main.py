# main.py
# Pipeline principal para an√°lise e predi√ß√£o de c√¢ncer de mama
# Este script executa todas as etapas: carregamento, pr√©-processamento, treinamento, avalia√ß√£o, interpreta√ß√£o e salvamento dos modelos.
# Cada etapa √© explicada detalhadamente nos coment√°rios abaixo.
#
# Autor: [Seu Nome]
# Data: [Data de modifica√ß√£o]

from preprocessing import load_and_clean_data, preprocess_data, split_data  # Fun√ß√µes para preparar os dados
from train import train_all_models  # Fun√ß√£o para treinar modelos padr√£o
from evaluate import evaluate_models, plot_feature_importance, explain_with_shap  # Fun√ß√µes para avaliar e interpretar modelos
from optimize import optimize_logistic_regression, optimize_decision_tree  # Fun√ß√µes para otimizar modelos
import pandas as pd
import joblib  # Para salvar e carregar modelos treinados
import os
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report
from train_top_features import get_top_n_features, filter_features

def main():
    print("üöÄ INICIANDO PIPELINE...\n")

    # Etapa 1: Carregamento e pr√©-processamento dos dados
    # L√™ o arquivo CSV, remove colunas desnecess√°rias, codifica e normaliza os dados
    df = load_and_clean_data()
    X, y = preprocess_data(df)
    X_train, X_test, y_train, y_test = split_data(X, y)
    print(f"‚úîÔ∏è Treino: {X_train.shape[0]} | Teste: {X_test.shape[0]}")


    # Etapa 2: Treinamento dos modelos padr√£o (sem otimiza√ß√£o de hiperpar√¢metros)
    print("\nü§ñ TREINANDO MODELOS PADR√ÉO...")
    models_default = train_all_models(X_train, y_train)

    # Etapa 3: Treinamento dos modelos otimizados (com busca de melhores hiperpar√¢metros)
    print("\nüîß OTIMIZANDO MODELOS COM VALIDA√á√ÉO CRUZADA...")
    models_optimized = {
        "Logistic Regression": optimize_logistic_regression(X_train, y_train),
        "Decision Tree": optimize_decision_tree(X_train, y_train)
    }

    # Etapa 4: Avalia√ß√£o dos modelos padr√£o e otimizados
    print("\nüìä AVALIANDO MODELOS PADR√ÉO...")
    evaluate_models(models_default, X_test, y_test)

    print("\nüìä AVALIANDO MODELOS OTIMIZADOS...")
    evaluate_models(models_optimized, X_test, y_test)

    # Etapa 5: Interpreta√ß√£o da import√¢ncia das vari√°veis (feature importance) para a √°rvore otimizada
    print("\nüåø INTERPRETANDO √ÅRVORE DE DECIS√ÉO (OTIMIZADA)...")
    # L√™ os nomes das colunas do arquivo original para exibir no gr√°fico
    feature_names = pd.read_csv('data/data.csv').drop(columns=['Unnamed: 32', 'id', 'diagnosis']).columns
    plot_feature_importance(models_optimized["Decision Tree"], feature_names, model_name="Decision_Tree_Optimizada")

    # Etapa 6: Explica√ß√£o do modelo de regress√£o log√≠stica otimizada usando SHAP
    print("\nüß† Explicando Regress√£o Log√≠stica (otimizada) com SHAP...")
    explain_with_shap(models_optimized["Logistic Regression"], X_train, feature_names, model_name="Regressao_Logistica_Otimizada")

    print("\n‚úÖ Pipeline finalizado com sucesso.")

    # Etapa 7: Salvar os modelos otimizados em arquivos para uso futuro
    print("\nüíæ Salvando modelos otimizados...")
    os.makedirs("outputs/models", exist_ok=True)  # Cria a pasta se n√£o existir
    joblib.dump(models_optimized["Logistic Regression"], "outputs/models/regression_optimized.pkl")
    joblib.dump(models_optimized["Decision Tree"], "outputs/models/tree_optimized.pkl")
    print("üìÅ Modelos salvos em: outputs/models/")

    print("\n‚úÖ Pipeline finalizado com sucesso.")

    # Etapa opcional: testar performance com as top-N features da √Årvore de Decis√£o
    print("\nüß™ Testando modelo com as 10 vari√°veis mais importantes...")

    # Recupera nomes das colunas
    feature_names = pd.read_csv('data/data.csv').drop(columns=['Unnamed: 32', 'id', 'diagnosis']).columns

    # Treina modelo completo com todas as features para pegar import√¢ncias
    full_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)
    top_10_features = get_top_n_features(full_tree, feature_names, n=4)
    print("üèÜ Top 10 features:", top_10_features)

    # Filtra os dados de treino e teste com as top 10
    X_train_top = filter_features(X_train, feature_names, top_10_features)
    X_test_top = filter_features(X_test, feature_names, top_10_features)

    # Treina novo modelo com top 10
    model_top = DecisionTreeClassifier(random_state=42)
    model_top.fit(X_train_top, y_train)
    y_pred_top = model_top.predict(X_test_top)

    # Avalia o desempenho
    print("\nüìä Avalia√ß√£o com Top-10 Features")
    print("Accuracy:", accuracy_score(y_test, y_pred_top))
    print("Recall:", recall_score(y_test, y_pred_top))
    print("F1-score:", f1_score(y_test, y_pred_top))
    print("\nClassification Report:\n", classification_report(y_test, y_pred_top))

if __name__ == "__main__":
    main()