# optimize.py
# Fun√ß√µes para otimizar modelos de classifica√ß√£o usando busca em grade (GridSearchCV)
# Explica√ß√µes detalhadas para cada fun√ß√£o
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import make_scorer, f1_score
import numpy as np
from xgboost import XGBClassifier

def optimize_decision_tree(X, y):
    """
    Otimiza os hiperpar√¢metros da √Årvore de Decis√£o usando GridSearchCV.
    Testa v√°rias combina√ß√µes de par√¢metros para encontrar a melhor √°rvore.
    Retorna o melhor modelo encontrado.
    """
    print("üå≥ Otimizando √Årvore de Decis√£o com GridSearchCV...")

    params = {
        'max_depth': [3, 5, 10, None],  # Profundidade m√°xima da √°rvore
        'min_samples_split': [2, 5, 10],  # M√≠nimo de amostras para dividir um n√≥
        'criterion': ['gini', 'entropy']  # Crit√©rio de divis√£o
    }

    grid = GridSearchCV(
        DecisionTreeClassifier(random_state=42),
        param_grid=params,
        scoring='f1',  # Usa F1-score como m√©trica principal
        cv=5,  # Valida√ß√£o cruzada com 5 divis√µes
        n_jobs=-1  # Usa todos os n√∫cleos dispon√≠veis
    )

    grid.fit(X, y)
    print("‚úîÔ∏è  Melhor √°rvore encontrada:", grid.best_params_)
    return grid.best_estimator_

def optimize_random_forest(X, y):
    """
    Otimiza os hiperpar√¢metros da Regress√£o Log√≠stica usando GridSearchCV.
    Testa diferentes valores de regulariza√ß√£o e solvers.
    Retorna o melhor modelo encontrado.
    """
    print("üìà Otimizando Random Forest com GridSearchCV...")

    params = {
        'n_estimators': [50, 100, 200], # N√∫mero de √°rvores
        'max_depth': [None, 10, 20],   # Profundidade m√°xima da √°rvore
        'min_samples_split': [2, 5, 10]  # M√≠nimo de amostras para dividir um n√≥
    }

    grid = GridSearchCV(
        RandomForestClassifier(random_state=42),
        param_grid=params,
        scoring='f1',
        cv=5,
        n_jobs=-1
    )

    grid.fit(X, y)
    print("‚úîÔ∏è  Melhor random forest encontrada:", grid.best_params_)
    return grid.best_estimator_

def optimize_logistic_regression(X, y):
    """
    Otimiza os hiperpar√¢metros da Regress√£o Log√≠stica usando GridSearchCV.
    Testa diferentes valores de regulariza√ß√£o e solvers.
    Retorna o melhor modelo encontrado.
    """
    print("üìà Otimizando Regress√£o Log√≠stica com GridSearchCV...")

    params = {
        'C': [0.01, 0.1, 1, 10],  # Par√¢metro de regulariza√ß√£o
        'penalty': ['l2'],  # Tipo de penalidade
        'solver': ['lbfgs', 'liblinear']  # Algoritmos de otimiza√ß√£o
    }

    grid = GridSearchCV(
        LogisticRegression(max_iter=1000, random_state=42),
        param_grid=params,
        scoring='f1',
        cv=5,
        n_jobs=-1
    )

    grid.fit(X, y)
    print("‚úîÔ∏è  Melhor regress√£o encontrada:", grid.best_params_)
    return grid.best_estimator_

def optimize_xgboost(X, y):
    """
    Otimiza os hiperpar√¢metros do XGBoost usando GridSearchCV.
    Testa diferentes combina√ß√µes de taxa de aprendizado e profundidade m√°xima.
    Retorna o melhor modelo encontrado.
    """
    print("üöÄ Otimizando XGBoost com GridSearchCV...")

    params = {
        'n_estimators': [50, 100, 200], # N√∫mero de √°rvores
        'learning_rate': [0.01, 0.1, 0.2], # Taxa de aprendizado
        'max_depth': [3, 5, 7] # Profundidade m√°xima da √°rvore
    }

    grid = GridSearchCV(
        XGBClassifier(eval_metric='logloss', random_state=42),
        param_grid=params,
        scoring='f1',
        cv=5,
        n_jobs=-1
    )

    grid.fit(X, y)
    print("‚úîÔ∏è  Melhor XGBoost encontrado:", grid.best_params_)
    return grid.best_estimator_

def optimize_knn(X, y):
    """
    Otimiza os hiperpar√¢metros do K-Nearest Neighbors (KNN) usando GridSearchCV.
    Testa diferentes valores para o n√∫mero de vizinhos.
    Retorna o melhor modelo encontrado.
    """
    print("üèÉ Otimizando KNN com GridSearchCV...")

    # Como o KNN √© sens√≠vel √† escala, √© ideal usar um pipeline
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('knn', KNeighborsClassifier())
    ])

    params = {
        'knn__n_neighbors': [3, 5, 7, 9], # N√∫mero de vizinhos
        'knn__weights': ['uniform', 'distance'] # Peso dos vizinhos
    }

    grid = GridSearchCV(
        pipe,
        param_grid=params,
        scoring='f1',
        cv=5,
        n_jobs=-1
    )

    grid.fit(X, y)
    print("‚úîÔ∏è  Melhor KNN encontrado:", grid.best_params_)
    return grid.best_estimator_

def optimize_svm(X, y):
    """
    Otimiza os hiperpar√¢metros do Support Vector Machine (SVM) usando GridSearchCV.
    Testa diferentes kernels e valores de regulariza√ß√£o (C).
    Retorna o melhor modelo encontrado.
    """
    print("üõ°Ô∏è Otimizando SVM com GridSearchCV...")
    
    # O SVM tamb√©m √© sens√≠vel √† escala, usamos um pipeline
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(random_state=42))
    ])

    params = {
        'svm__C': [0.1, 1, 10], # Par√¢metro de regulariza√ß√£o
        'svm__kernel': ['linear', 'rbf', 'poly'] # Tipos de kernel
    }

    grid = GridSearchCV(
        pipe,
        param_grid=params,
        scoring='f1',
        cv=5,
        n_jobs=-1
    )

    grid.fit(X, y)
    print("‚úîÔ∏è  Melhor SVM encontrado:", grid.best_params_)
    return grid.best_estimator_

def evaluate_model_with_cv(model, X, y, scoring='f1'):
    """
    Avalia um modelo usando valida√ß√£o cruzada (cross-validation) e imprime a m√©dia e desvio padr√£o da m√©trica escolhida.
    scoring: m√©trica a ser usada (padr√£o: f1)
    """
    print(f"\nü™™ Avaliando com cross-validation (scoring = {scoring})...")
    scores = cross_val_score(model, X, y, cv=5, scoring=scoring)
    print(f"‚úîÔ∏è  {scoring}-score m√©dio: {np.mean(scores):.4f} ¬± {np.std(scores):.4f}")